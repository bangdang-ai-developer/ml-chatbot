"""
Smart Response Router
Intelligently routes queries to appropriate response strategies
"""

from typing import Dict, Any, List, Optional, Tuple
import logging
import asyncio
from dataclasses import dataclass

from .query_intent_classifier import QueryIntentClassifier, IntentAnalysis, QueryIntent
from .ai_service import GeminiAIService
from .rag_service import RAGService

logger = logging.getLogger(__name__)

@dataclass
class ResponseResult:
    """Result of intelligent response generation"""
    response: str
    strategy_used: str
    sources: List[Dict[str, Any]]
    confidence: float
    citations: List[Dict[str, Any]]
    explanation: str
    processing_time: float

class SmartResponseRouter:
    """
    Intelligent router that combines RAG and general AI knowledge
    """

    def __init__(self, rag_service: RAGService, ai_service: GeminiAIService):
        self.rag_service = rag_service
        self.ai_service = ai_service
        self.intent_classifier = QueryIntentClassifier()

        # Templates for hybrid responses
        self.hybrid_templates = {
            'vietnamese': {
                'introduction': "ChÃ o báº¡n, Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i cá»§a báº¡n, mÃ¬nh sáº½ káº¿t há»£p thÃ´ng tin tá»« tÃ i liá»‡u vÃ  kiáº¿n thá»©c chung:",
                'document_section': "\nðŸ“š **Tá»« tÃ i liá»‡u tham kháº£o:**\n{document_content}",
                'general_section': "\nðŸ¤– **Tá»« kiáº¿n thá»©c tá»•ng quan:**\n{general_content}",
                'conclusion': "\nHy vá»ng thÃ´ng tin nÃ y há»¯u Ã­ch cho báº¡n! Báº¡n cÃ³ muá»‘n mÃ¬nh giáº£i thÃ­ch sÃ¢u hÆ¡n pháº§n nÃ o khÃ´ng?"
            },
            'english': {
                'introduction': "Hello! To answer your question, I'll combine information from documents with general knowledge:",
                'document_section': "\nðŸ“š **From referenced documents:**\n{document_content}",
                'general_section': "\nðŸ¤– **From general knowledge:**\n{general_content}",
                'conclusion': "\nI hope this information is helpful! Would you like me to explain any part in more detail?"
            }
        }

    async def generate_intelligent_response(
        self,
        query: str,
        query_analysis: Dict[str, Any],
        session_id: str = "default"
    ) -> ResponseResult:
        """
        Generate intelligent response using optimal strategy
        """
        start_time = asyncio.get_event_loop().time()

        try:
            # Classify query intent
            intent_analysis = self.intent_classifier.classify_intent(query, query_analysis)

            # Get response strategy with reasonable default context quality
            # For deep learning queries with both books indexed, use higher context quality
            default_context_quality = 0.5  # Default to moderate quality for hybrid queries
            if intent_analysis.intent.value in ['hybrid'] and any(keyword in query.lower() for keyword in ['deep learning', 'há»c sÃ¢u', 'neural network', 'máº¡ng nÆ¡-ron']):
                default_context_quality = 0.7  # Higher quality for ML/DL specific queries

            strategy = self.intent_classifier.get_response_strategy(intent_analysis, default_context_quality)

            logger.info(f"Query: '{query[:50]}...' - Intent: {intent_analysis.intent.value}, Strategy: {strategy}")

            # Generate response based on strategy
            if strategy['primary_source'] == 'documents':
                result = await self._generate_rag_response(query, intent_analysis, session_id)
            elif strategy['primary_source'] == 'ai_knowledge':
                result = await self._generate_general_knowledge_response(query, intent_analysis, session_id)
            elif strategy['primary_source'] == 'hybrid':
                result = await self._generate_hybrid_response(query, intent_analysis, session_id, strategy)
            elif strategy['primary_source'] == 'conversational':
                result = await self._generate_conversational_response(query, intent_analysis, session_id)
            else:
                # Fallback to hybrid
                result = await self._generate_hybrid_response(query, intent_analysis, session_id, strategy)

            # Update processing time
            result.processing_time = asyncio.get_event_loop().time() - start_time

            return result

        except Exception as e:
            logger.error(f"Error in intelligent response generation: {e}")
            # Fallback response
            processing_time = asyncio.get_event_loop().time() - start_time
            return ResponseResult(
                response="Xin lá»—i, mÃ¬nh gáº·p lá»—i khi xá»­ lÃ½ cÃ¢u há»i cá»§a báº¡n. Báº¡n cÃ³ thá»ƒ thá»­ láº¡i khÃ´ng?",
                strategy_used="fallback",
                sources=[],
                confidence=0.1,
                citations=[],
                explanation="Error occurred, used fallback response",
                processing_time=processing_time
            )

    async def _generate_rag_response(
        self,
        query: str,
        intent_analysis: IntentAnalysis,
        session_id: str
    ) -> ResponseResult:
        """Generate response using RAG approach"""
        try:
            # Get documents from RAG service
            doc_result = await self.rag_service.retrieve_documents_for_query(query)

            if not doc_result['has_content']:
                # No relevant documents, fallback to general knowledge
                return await self._generate_general_knowledge_response(query, intent_analysis, session_id)

            # Generate response using AI service with context
            ai_response = await self.ai_service.generate_response(
                query=query,
                context=doc_result['context_texts']
            )

            return ResponseResult(
                response=ai_response,
                strategy_used="rag_only",
                sources=doc_result['sources'],
                confidence=intent_analysis.confidence,
                citations=doc_result['sources'],
                explanation=f"Used RAG approach - {intent_analysis.reasoning}",
                processing_time=0.0  # Will be set by caller
            )

        except Exception as e:
            logger.error(f"RAG response generation failed: {e}")
            # Fallback to general knowledge
            return await self._generate_general_knowledge_response(query, intent_analysis, session_id)

    async def _generate_general_knowledge_response(
        self,
        query: str,
        intent_analysis: IntentAnalysis,
        session_id: str
    ) -> ResponseResult:
        """Generate response using general AI knowledge"""
        try:
            # Create prompt for general knowledge response
            is_vietnamese = intent_analysis.specific_entities and any(
                'vietnamese' in str(entity).lower() or 'chÃ o' in query.lower() for entity in intent_analysis.specific_entities
            ) or self._is_vietnamese_query(query)

            if is_vietnamese:
                prompt = self._create_vietnamese_general_prompt(query, intent_analysis)
            else:
                prompt = self._create_english_general_prompt(query, intent_analysis)

            # Generate response using AI service
            response = await self.ai_service.chat_completion([
                {"role": "system", "content": prompt},
                {"role": "user", "content": query}
            ])

            return ResponseResult(
                response=response,
                strategy_used="general_knowledge",
                sources=[],
                confidence=intent_analysis.confidence,
                citations=[],
                explanation=f"Used general AI knowledge - {intent_analysis.reasoning}",
                processing_time=0.0  # Will be set by caller
            )

        except Exception as e:
            logger.error(f"General knowledge response generation failed: {e}")
            # Ultimate fallback
            return ResponseResult(
                response="Xin lá»—i, mÃ¬nh khÃ´ng thá»ƒ tráº£ lá»i cÃ¢u há»i nÃ y lÃºc nÃ y. Báº¡n cÃ³ thá»ƒ thá»­ láº¡i hoáº·c há»i cÃ¢u khÃ¡c khÃ´ng?",
                strategy_used="ultimate_fallback",
                sources=[],
                confidence=0.1,
                citations=[],
                explanation="General knowledge failed, using ultimate fallback",
                processing_time=0.0
            )

    async def _generate_hybrid_response(
        self,
        query: str,
        intent_analysis: IntentAnalysis,
        session_id: str,
        strategy: Dict[str, Any]
    ) -> ResponseResult:
        """Generate hybrid response combining RAG and general knowledge"""
        try:
            # Get both RAG and general knowledge responses
            rag_task = None
            general_task = None

            if strategy.get('use_rag', False):
                rag_task = asyncio.create_task(
                    self.rag_service.retrieve_documents_for_query(query)
                )

            if strategy.get('use_general_knowledge', False):
                general_task = asyncio.create_task(
                    self._generate_general_knowledge_response(query, intent_analysis, session_id)
                )

            # Wait for results
            doc_result = None
            general_response = None

            if rag_task:
                try:
                    doc_result = await rag_task
                except Exception as e:
                    logger.warning(f"RAG document retrieval failed in hybrid mode: {e}")

            if general_task:
                try:
                    general_response = await general_task
                except Exception as e:
                    logger.warning(f"General knowledge response failed in hybrid mode: {e}")

            # Combine responses intelligently
            if doc_result and doc_result['has_content']:
                # We have RAG content, generate response with context
                try:
                    ai_response = await self.ai_service.generate_response(
                        query=query,
                        context=doc_result['context_texts']
                    )

                    return ResponseResult(
                        response=ai_response,
                        strategy_used="hybrid_with_rag",
                        sources=doc_result['sources'],
                        confidence=intent_analysis.confidence,
                        citations=doc_result['sources'],
                        explanation=f"Used hybrid approach with RAG context - {intent_analysis.reasoning}",
                        processing_time=0.0  # Will be set by caller
                    )
                except Exception as e:
                    logger.error(f"Hybrid AI response generation failed: {e}")
                    # Fallback to general knowledge
                    if general_response:
                        return general_response
                    else:
                        return await self._generate_general_knowledge_response(query, intent_analysis, session_id)
            else:
                # No RAG content, use general knowledge
                if general_response:
                    return general_response
                else:
                    return await self._generate_general_knowledge_response(query, intent_analysis, session_id)

        except Exception as e:
            logger.error(f"Hybrid response generation failed: {e}")
            # Ultimate fallback
            return await self._generate_general_knowledge_response(query, intent_analysis, session_id)

    async def _generate_conversational_response(
        self,
        query: str,
        intent_analysis: IntentAnalysis,
        session_id: str
    ) -> ResponseResult:
        """Generate conversational response"""
        conversational_responses = {
            'hello': "ChÃ o báº¡n! MÃ¬nh lÃ  ngÆ°á»i hÆ°á»›ng dáº«n vá» Machine Learning. Báº¡n cÃ³ cÃ¢u há»i gÃ¬ vá» ML/AI khÃ´ng?",
            'hi': "Xin chÃ o! Ráº¥t vui Ä‘Æ°á»£c trÃ² chuyá»‡n vá»›i báº¡n. Báº¡n muá»‘n tÃ¬m hiá»ƒu vá» chá»§ Ä‘á» gÃ¬ hÃ´m nay?",
            'thanks': "KhÃ´ng cÃ³ gÃ¬! MÃ¬nh ráº¥t vui Ä‘Æ°á»£c giÃºp Ä‘á»¡ báº¡n. Báº¡n cÃ²n cÃ¢u há»i nÃ o khÃ¡c khÃ´ng?",
            'goodbye': "Táº¡m biá»‡t! ChÃºc báº¡n há»c táº­p hiá»‡u quáº£. HÃ£y quay láº¡i anytime nhÃ©!",
            'help': "ChÃ o báº¡n! MÃ¬nh cÃ³ thá»ƒ giÃºp báº¡n vá» cÃ¡c chá»§ Ä‘á» Machine Learning, AI, Neural Networks, Deep Learning vÃ  nhiá»u hÆ¡n ná»¯a. Báº¡n muá»‘n biáº¿t vá» gÃ¬?"
        }

        query_lower = query.lower().strip()
        response = conversational_responses.get(query_lower, "ChÃ o báº¡n! MÃ¬nh cÃ³ thá»ƒ giÃºp gÃ¬ cho báº¡n vá» Machine Learning vÃ  AI?")

        return ResponseResult(
            response=response,
            strategy_used="conversational",
            sources=[],
            confidence=1.0,
            citations=[],
            explanation="Conversational response pattern matched",
            processing_time=0.0
        )

    def _combine_responses(
        self,
        rag_response: Optional[Dict],
        general_response: Optional[ResponseResult],
        intent_analysis: IntentAnalysis,
        original_query: str
    ) -> Dict[str, str]:
        """Intelligently combine RAG and general knowledge responses"""

        is_vietnamese = self._is_vietnamese_query(original_query)
        templates = self.hybrid_templates['vietnamese' if is_vietnamese else 'english']

        combined_text = templates['introduction']

        # Add RAG content if available
        if rag_response and rag_response.get('response'):
            document_content = rag_response['response']
            # Check if RAG provided meaningful content
            if len(document_content) > 100 and "khÃ´ng cÃ³" not in document_content.lower():
                combined_text += templates['document_section'].format(document_content=document_content)
            else:
                # RAG didn't provide useful content
                rag_response = None

        # Add general knowledge content if available
        if general_response and general_response.response:
            general_content = general_response.response
            # Avoid duplication
            if not rag_response or len(general_content) > len(rag_response.get('response', '')):
                combined_text += templates['general_section'].format(general_content=general_content)

        # Add conclusion
        combined_text += templates['conclusion']

        explanation_parts = []
        if rag_response:
            explanation_parts.append("Used document-specific information")
        if general_response:
            explanation_parts.append("Enhanced with general AI knowledge")
        if not rag_response and not general_response:
            explanation_parts.append("Used default response")

        return {
            'text': combined_text,
            'explanation': f"Hybrid approach: {', '.join(explanation_parts)} - {intent_analysis.reasoning}"
        }

    def _create_vietnamese_general_prompt(self, query: str, intent_analysis: IntentAnalysis) -> str:
        """Create prompt for Vietnamese general knowledge response"""
        return f"""Báº¡n lÃ  má»™t ngÆ°á»i hÆ°á»›ng dáº«n chuyÃªn nghiá»‡p vá» Machine Learning vÃ  AI. HÃ£y tráº£ lá»i cÃ¢u há»i sau má»™t cÃ¡ch tá»± nhiÃªn, thÃ¢n thiá»‡n vÃ  chÃ­nh xÃ¡c.

CÃ¢u há»i: {query}

HÆ°á»›ng dáº«n:
1. Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t tá»± nhiÃªn
2. Cung cáº¥p thÃ´ng tin chÃ­nh xÃ¡c vÃ  cáº­p nháº­t
3. DÃ¹ng vÃ­ dá»¥ thá»±c táº¿ Ä‘á»ƒ minh há»a
4. Giáº£i thÃ­ch cÃ¡c khÃ¡i niá»‡m phá»©c táº¡p má»™t cÃ¡ch dá»… hiá»ƒu
5. Náº¿u Ä‘Ã¢y lÃ  khÃ¡i niá»‡m cÆ¡ báº£n, giáº£i thÃ­ch tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i
6. Duy trÃ¬ phong cÃ¡ch trÃ² chuyá»‡n thÃ¢n thiá»‡n

Tráº£ lá»i tháº­t tá»± nhiÃªn nhÆ° Ä‘ang nÃ³i chuyá»‡n vá»›i báº¡n há»c!"""

    def _create_english_general_prompt(self, query: str, intent_analysis: IntentAnalysis) -> str:
        """Create prompt for English general knowledge response"""
        return f"""You are a professional guide for Machine Learning and AI. Answer the following question naturally, friendly, and accurately.

Question: {query}

Guidelines:
1. Provide accurate, up-to-date information
2. Use practical examples to illustrate concepts
3. Explain complex concepts in an easy-to-understand way
4. For fundamental concepts, provide comprehensive explanations
5. Maintain a conversational, friendly tone

Answer naturally as if talking to a learner!"""

    def _is_vietnamese_query(self, query: str) -> bool:
        """Simple check if query is in Vietnamese"""
        vietnamese_chars = set('Ã¡Ã áº£Ã£áº¡áº¥áº§áº©áº«áº­áº¯áº±áº³áºµáº·Ã©Ã¨áº»áº½áº¹áº¿á»á»ƒá»…á»‡Ã­Ã¬á»‰Ä©á»‹Ã³Ã²á»Ãµá»á»‘á»“á»•á»—á»™á»›á»á»Ÿá»¡á»£ÃºÃ¹á»§Å©á»¥á»©á»«á»­á»¯á»±Ã½á»³á»·á»¹á»µ')
        return any(char in vietnamese_chars for char in query.lower())

    async def get_routing_statistics(self) -> Dict[str, Any]:
        """Get statistics about routing decisions"""
        # This could be expanded to track actual usage patterns
        return {
            'supported_intents': [intent.value for intent in QueryIntent],
            'routing_strategies': ['rag_only', 'general_knowledge', 'hybrid', 'conversational'],
            'hybrid_enabled': True,
            'fallback_mechanisms': ['general_knowledge_fallback', 'ultimate_fallback']
        }